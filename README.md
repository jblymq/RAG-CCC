# RAG æ¡†æ¶ - ä¼ä¸šçº§æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/jblymq/RAG-CCC#)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![C++17](https://img.shields.io/badge/C%2B%2B-17-blue.svg)](https://isocpp.org/std/the-standard)
[![Platform](https://img.shields.io/badge/platform-Linux%20%7C%20macOS%20%7C%20Windows-lightgrey)](https://github.com/jblymq/RAG-CCC#)
[![SQLite](https://img.shields.io/badge/SQLite-3.35%2B-blue)](https://sqlite.org/)

ä¸€ä¸ªé«˜æ€§èƒ½ã€ä¼ä¸šçº§çš„C++17 RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ¡†æ¶ï¼Œæä¾›åŒæ¨¡å¼æ¶æ„ï¼šå†…å­˜BM25+HNSWèåˆæ£€ç´¢å’ŒSQLiteæŒä¹…åŒ–çŸ¢é‡æ•°æ®åº“ã€‚æ”¯æŒå¤šè¯­è¨€æ–‡æ¡£å¤„ç†ã€æ™ºèƒ½ç¼“å­˜ã€è‡ªåŠ¨è°ƒä¼˜å’Œçƒ­é‡å»ºç­‰ç‰¹æ€§ã€‚

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

### ï¿½ å®Œæ•´çš„è®¾è®¡æ–‡æ¡£å¯¹æ ‡å®ç°
- âœ… **ä¸‰å±‚SQLiteæ¶æ„**ï¼šchunks + chunks_fts + embeddings
- âœ… **æ··åˆæ£€ç´¢æµç¨‹**ï¼šFTS5 (Top Kâ‚) + Vector (Top Kâ‚‚) å¹¶è¡Œæ‰§è¡Œ
- âœ… **ACIDäº‹åŠ¡ä¿è¯**ï¼šæ•°æ®ä¸€è‡´æ€§å’Œå¯é æ€§
- âœ… **WALæ¨¡å¼ä¼˜åŒ–**ï¼šé«˜å¹¶å‘æ€§èƒ½å’Œçƒ­å¤‡ä»½
- âœ… **åŠ¨æ€å‚æ•°è°ƒä¼˜**ï¼šKâ‚, Kâ‚‚ è‡ªé€‚åº”ä¼˜åŒ–

### ğŸš€ åŒæ¨¡å¼æ¶æ„

#### ğŸ§  å†…å­˜æ¨¡å¼ - æè‡´æ€§èƒ½
- **BM25+HNSWèåˆ**ï¼šå¾®ç§’çº§æ£€ç´¢å“åº”ï¼ˆ160-300Î¼sï¼‰
- **å¼‚æ­¥å¹¶å‘æŸ¥è¯¢**ï¼šå¤šæŸ¥è¯¢å¹¶è¡Œå¤„ç†ï¼Œ3æŸ¥è¯¢ä»…éœ€0.3ms
- **æ™ºèƒ½ç¼“å­˜**ï¼šLRU+TTLï¼Œ9å€æŸ¥è¯¢åŠ é€Ÿ
- **5ç§èåˆç­–ç•¥**ï¼šBM25_ONLY, VECTOR_ONLY, HYBRID, RRF, ADAPTIVE

#### ğŸ—„ï¸ SQLiteæ¨¡å¼ - ä¼ä¸šçº§æŒä¹…åŒ–
- **FTS5å…¨æ–‡æ£€ç´¢**ï¼šå®Œæ•´BM25ç®—æ³•ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆ
- **å‘é‡æ‰©å±•æ”¯æŒ**ï¼šsqlite-vec/sqlite-vssé›†æˆ
- **ä¸‰å±‚å­˜å‚¨æ¶æ„**ï¼šåŸæ–‡ã€å…¨æ–‡ç´¢å¼•ã€å‘é‡ç´¢å¼•åˆ†ç¦»
- **äº‹åŠ¡ACIDä¿è¯**ï¼šæ•°æ®ä¸€è‡´æ€§å’Œæ•…éšœæ¢å¤
- **åœ¨çº¿çƒ­é‡å»º**ï¼šæ— åœæœºç´¢å¼•æ›´æ–°

### ğŸŒ å¤šè¯­è¨€ä¸å›½é™…åŒ–
- **æ™ºèƒ½åˆ†è¯å™¨**ï¼šä¸­è‹±æ–‡æ··åˆæ–‡æ¡£å¤„ç†
- **è¯­è¨€è‡ªåŠ¨æ£€æµ‹**ï¼šè‡ªé€‚åº”åˆ†è¯ç­–ç•¥
- **Unicodeæ”¯æŒ**ï¼šå®Œæ•´çš„å›½é™…åŒ–å­—ç¬¦å¤„ç†
- **åœç”¨è¯è¿‡æ»¤**ï¼šå¯é…ç½®çš„å¤šè¯­è¨€åœç”¨è¯åº“

### âš¡ é«˜æ€§èƒ½ç‰¹æ€§
- **çº¿ç¨‹æ± æ¶æ„**ï¼šåŸºäºfutureçš„å¼‚æ­¥ä»»åŠ¡è°ƒåº¦
- **æ™ºèƒ½ç¼“å­˜**ï¼šå¤šçº§ç¼“å­˜ç­–ç•¥ï¼Œå¹³å‡3-9å€æ€§èƒ½æå‡
- **å†…å­˜ä¼˜åŒ–**ï¼šé›¶æ‹·è´è®¾è®¡ï¼Œæœ€å°åŒ–å†…å­˜åˆ†é…
- **æ‰¹å¤„ç†ä¼˜åŒ–**ï¼šå¤§è§„æ¨¡æ–‡æ¡£çš„é«˜æ•ˆæ‰¹é‡å¤„ç†

### ğŸ”§ ä¼ä¸šçº§ç‰¹æ€§
- **é…ç½®é©±åŠ¨**ï¼šTOMLé…ç½®æ–‡ä»¶ï¼Œæ— éœ€é‡ç¼–è¯‘
- **ç›‘æ§å‹å¥½**ï¼šä¸°å¯Œçš„æ€§èƒ½æŒ‡æ ‡å’ŒçŠ¶æ€ç›‘æ§
- **æ‰©å±•æ¥å£**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰ç»„ä»¶
- **è¿ç»´å·¥å…·**ï¼šæ•°æ®åº“ç»´æŠ¤ã€å¤‡ä»½å’Œè¿ç§»å·¥å…·

### ğŸš€ æ··åˆRAGç‰¹æ€§ ğŸ”¥
- **æ™ºèƒ½åˆ†å±‚**ï¼šçƒ­æ•°æ®å†…å­˜ç¼“å­˜ + å†·æ•°æ®æŒä¹…åŒ–å­˜å‚¨
- **æ— é™å®¹é‡**ï¼šå†…å­˜å±‚é«˜æ€§èƒ½ + SQLiteå±‚å¤§å®¹é‡å­˜å‚¨
- **è‡ªåŠ¨ä¼˜åŒ–**ï¼šåŸºäºè®¿é—®æ¨¡å¼çš„æ™ºèƒ½æ•°æ®è¿ç§»
- **é€æ˜åˆ‡æ¢**ï¼šç”¨æˆ·æ— æ„ŸçŸ¥çš„åŒå±‚æ£€ç´¢æ¶æ„
- **å¹¶è¡Œæ£€ç´¢**ï¼šåŒæ—¶æœç´¢å†…å­˜å’ŒSQLiteï¼Œæ™ºèƒ½ç»“æœåˆå¹¶

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RAG æ¡†æ¶                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨å±‚  â”‚  Agent  â”‚  Tools  â”‚  MCP Protocol â”‚  Planning    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          â”‚         å†…å­˜æ¨¡å¼         â”‚        SQLiteæ¨¡å¼        â”‚
â”‚  æ£€ç´¢å±‚  â”‚  BM25 + HNSW èåˆæ£€ç´¢    â”‚  FTS5 + Vector æ··åˆæ£€ç´¢  â”‚
â”‚          â”‚  å¼‚æ­¥å¹¶å‘ + æ™ºèƒ½ç¼“å­˜      â”‚  äº‹åŠ¡ä¿æŠ¤ + æŒä¹…åŒ–å­˜å‚¨    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å±‚  â”‚  Tokenizer â”‚ ThreadPool â”‚ LRUCache â”‚ AutoTuner   â”‚
â”‚          â”‚  å¤šè¯­è¨€åˆ†è¯  â”‚  çº¿ç¨‹æ± ç®¡ç†  â”‚  ç¼“å­˜ç³»ç»Ÿ  â”‚  è‡ªåŠ¨è°ƒä¼˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SQLite ä¸‰å±‚å­˜å‚¨æ¶æ„

```sql
-- 1. ä¸»è¡¨ï¼šå­˜å‚¨åŸæ–‡ä¸å…ƒä¿¡æ¯
CREATE TABLE chunks (
    id        INTEGER PRIMARY KEY,
    doc_id    TEXT NOT NULL,
    seq_no    INTEGER,
    topic     TEXT,
    content   TEXT NOT NULL,
    language  TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 2. FTS5 è™šæ‹Ÿè¡¨ï¼šBM25å…¨æ–‡æ£€ç´¢
CREATE VIRTUAL TABLE chunks_fts USING fts5(
    content,
    content='chunks',
    content_rowid='id',
    tokenize='unicode61 remove_diacritics 1'
);

-- 3. å‘é‡ç´¢å¼•è¡¨ï¼šé«˜ç»´å‘é‡å­˜å‚¨
CREATE TABLE embeddings (
    chunk_id  INTEGER PRIMARY KEY,
    vector    BLOB,  -- 768ç»´æµ®ç‚¹å‘é‡
    FOREIGN KEY(chunk_id) REFERENCES chunks(id)
);
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
rag/
â”œâ”€â”€ ğŸ“„ README.md                 # æœ¬æ–‡æ¡£
â”œâ”€â”€ âš™ï¸ rag_config.toml          # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ ğŸ“‹ INTEGRATION_SCENARIOS.md  # ä¸šåŠ¡é›†æˆåœºæ™¯
â”‚
â”œâ”€â”€ ğŸ§© æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ chunk.h                  # æ–‡æ¡£å—å®šä¹‰
â”‚   â”œâ”€â”€ config.h/.cpp           # é…ç½®ç®¡ç†å™¨
â”‚   â”œâ”€â”€ tokenizer.h/.cpp        # å¤šè¯­è¨€åˆ†è¯å™¨
â”‚   â”œâ”€â”€ bm25.h/.cpp            # BM25æ£€ç´¢å¼•æ“
â”‚   â”œâ”€â”€ fusion_retriever.h/.cpp # å†…å­˜èåˆæ£€ç´¢å™¨
â”‚   â”œâ”€â”€ sqlite_db.h/.cpp       # SQLiteæ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ sqlite_retriever.h/.cpp # SQLiteæ£€ç´¢å™¨
â”‚   â”œâ”€â”€ lru_cache.h/.cpp       # LRUç¼“å­˜ç³»ç»Ÿ
â”‚   â”œâ”€â”€ thread_pool.h/.cpp     # çº¿ç¨‹æ± ç®¡ç†
â”‚   â””â”€â”€ autotuner.h/.cpp       # è‡ªåŠ¨è°ƒä¼˜å™¨
â”‚
â”œâ”€â”€ ğŸ“š ä¾èµ–åº“
â”‚   â””â”€â”€ toml.hpp               # TOMLè§£æåº“
â”‚
â””â”€â”€ ğŸ¯ ç¤ºä¾‹ç¨‹åº
    â”œâ”€â”€ example/
    â”‚   â”œâ”€â”€ CMakeLists.txt     # æ„å»ºé…ç½®
    â”‚   â”œâ”€â”€ main.cpp          # ç»¼åˆæ¼”ç¤ºç¨‹åº
    â”‚   â”œâ”€â”€ hybrid_rag_demo.cpp # æ··åˆRAGç³»ç»Ÿæ¼”ç¤º ğŸ”¥
    â”‚   â”œâ”€â”€ rag_config.toml   # ç¤ºä¾‹é…ç½®
    â”‚   â””â”€â”€ build/            # æ„å»ºç›®å½•
    â””â”€â”€ INTEGRATION_SCENARIOS.md # é›†æˆæ¡ˆä¾‹æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

#### å¿…éœ€ä¾èµ–
- **C++17** å…¼å®¹ç¼–è¯‘å™¨ï¼ˆGCC 7+, Clang 6+, MSVC 2019+ï¼‰
- **CMake 3.10+** æ„å»ºç³»ç»Ÿ
- **SQLite 3.35+** æ•°æ®åº“ï¼ˆæ”¯æŒFTS5ï¼‰
- **pthread** å¤šçº¿ç¨‹æ”¯æŒ

#### å¯é€‰æ‰©å±•
- **sqlite-vec** æˆ– **sqlite-vss** å‘é‡æ‰©å±•ï¼ˆå¢å¼ºå‘é‡æ£€ç´¢ï¼‰
- **pkg-config** ç”¨äºä¾èµ–ç®¡ç†

### ä¸€é”®å®‰è£…ä¾èµ–

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install build-essential cmake libsqlite3-dev pkg-config

# CentOS/RHEL
sudo yum install gcc-c++ cmake sqlite-devel pkgconfig

# macOS
brew install cmake sqlite pkg-config

# éªŒè¯å®‰è£…
sqlite3 --version  # åº”æ˜¾ç¤º 3.35+ ç‰ˆæœ¬
```

### ç¼–è¯‘å®‰è£…

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/jblymq/RAG-CCC.git
cd /rag/example

# 2. åˆ›å»ºæ„å»ºç›®å½•
mkdir build && cd build

# 3. é…ç½®å’Œç¼–è¯‘
cmake ..
make -j$(nproc)

# 4. è¿è¡Œç»¼åˆæ¼”ç¤º
./rag_example
```

### é¢„æœŸè¾“å‡º

```
RAG ç³»ç»Ÿç»¼åˆæ¼”ç¤ºç¨‹åº
Retrieval-Augmented Generation System Demo

================================================================================
  å†…å­˜ RAG ç³»ç»Ÿæ¼”ç¤º
  BM25 + HNSW èåˆæ£€ç´¢
================================================================================
âœ… é…ç½®åŠ è½½å®Œæˆ (è€—æ—¶: 0.062ms)
âœ… æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: 0.006ms)
âœ… ç´¢å¼•æ„å»ºå®Œæˆ (6 ä¸ªæ–‡æ¡£å—, è€—æ—¶: 0.883ms)

ğŸ” æ£€ç´¢æµ‹è¯•
--------------------------------------------------
æŸ¥è¯¢: æœºå™¨å­¦ä¹ ç®—æ³•
  æ£€ç´¢è€—æ—¶: 255Î¼s
  æ‰¾åˆ°ç»“æœ: 3 ä¸ª
    1. doc3 (åˆ†æ•°: 0.5000)
    2. doc2 (åˆ†æ•°: 0.4994)

ğŸš€ å¼‚æ­¥æŸ¥è¯¢æ¼”ç¤º
------------------------------
å¼‚æ­¥æŸ¥è¯¢æ€»è€—æ—¶: 0.284ms

================================================================================
  SQLite RAG ç³»ç»Ÿæ¼”ç¤º
  FTS5 + Vector æŒä¹…åŒ–æ£€ç´¢
================================================================================
âœ… SQLite RAG ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ (è€—æ—¶: 0.482ms)
âœ… æ–‡æ¡£åŠ è½½å®Œæˆ (6/6 ä¸ªæ–‡æ¡£, è€—æ—¶: 7.231ms)

ğŸ“Š æ•°æ®åº“ç»Ÿè®¡
  æ–‡æ¡£æ•°é‡: 18
  å‘é‡æ•°é‡: 18
  æ•°æ®åº“å¤§å°: 0.11 MB

ğŸ’¾ ç¼“å­˜æ€§èƒ½æµ‹è¯•
------------------------------
  ç¬¬ä¸€æ¬¡æŸ¥è¯¢: 161Î¼s (ç¼“å­˜æœªå‘½ä¸­)
  ç¬¬äºŒæ¬¡æŸ¥è¯¢: 46Î¼s (ç¼“å­˜å‘½ä¸­)
  ç¼“å­˜åŠ é€Ÿæ¯”: 3.50x

ğŸ‰ RAG ç³»ç»Ÿç»¼åˆæ¼”ç¤ºå®Œæˆï¼
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

### å†…å­˜æ¨¡å¼å¿«é€Ÿä½“éªŒ

```cpp
#include "rag/config.h"
#include "rag/fusion_retriever.h"

int main() {
    using namespace rag;

    // 1. åŠ è½½é…ç½®
    auto config = ConfigLoader::load("./rag_config.toml");

    // 2. åˆ›å»ºæ–‡æ¡£
    std::vector<Chunk> docs;

    Chunk doc1;
    doc1.text = "Machine learning is a subset of artificial intelligence.";
    doc1.doc_id = "ml_intro";
    doc1.topic = "AI";
    doc1.language = "en";
    docs.push_back(doc1);

    Chunk doc2;
    doc2.text = "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒæ¨¡æ‹Ÿäººè„‘ç¥ç»ç½‘ç»œã€‚";
    doc2.doc_id = "dl_intro";
    doc2.topic = "æ·±åº¦å­¦ä¹ ";
    doc2.language = "zh";
    docs.push_back(doc2);

    // 3. åˆ›å»ºèåˆæ£€ç´¢å™¨
    auto retriever = FusionRetriever::from_config(*config);

    // 4. æ„å»ºç´¢å¼•
    retriever->fit(docs);

    // 5. æ‰§è¡ŒæŸ¥è¯¢
    auto results = retriever->query("artificial intelligence", 5);

    // 6. è¾“å‡ºç»“æœ
    for (const auto& result : results) {
        std::cout << "ğŸ“„ Doc: " << result.doc_id
                  << " | ğŸ“Š Score: " << std::fixed << std::setprecision(4)
                  << result.score << std::endl;
        std::cout << "ğŸ“ Content: " << result.text.substr(0, 100) << "..." << std::endl;
        std::cout << std::string(50, '-') << std::endl;
    }

    // 7. å¼‚æ­¥æŸ¥è¯¢æ¼”ç¤º
    auto future_result = retriever->query_async("deep learning", 3);
    auto async_results = future_result.get();
    std::cout << "ğŸš€ å¼‚æ­¥æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° " << async_results.size() << " ä¸ªç»“æœ" << std::endl;

    return 0;
}
```

    return 0;
}
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### 1. é…ç½®ç³»ç»Ÿ

RAGæ¡†æ¶ä½¿ç”¨TOMLæ ¼å¼çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒçƒ­é‡è½½å’Œæ¨¡å—åŒ–é…ç½®ï¼š

```toml
# rag_config.toml

[chunk]
size = 512            # æ–‡æ¡£å—å¤§å°
overlap = 128         # é‡å å¤§å°

[bm25]
k1 = 1.2             # BM25 k1å‚æ•°
b = 0.75             # BM25 bå‚æ•°

[hnsw]
M = 16               # HNSWè¿æ¥æ•°
ef_construction = 200 # æ„å»ºæ—¶efå‚æ•°
ef_query = 50        # æŸ¥è¯¢æ—¶efå‚æ•°

[fusion]
strategy = "HYBRID"   # èåˆç­–ç•¥ï¼šBM25_ONLY/VECTOR_ONLY/HYBRID/RRF
bm25_weight = 0.6    # BM25æƒé‡
vector_weight = 0.4   # å‘é‡æƒé‡
rrf_k = 60           # RRFå‚æ•°

[cache]
capacity = 1000      # ç¼“å­˜å®¹é‡
ttl_seconds = 3600   # è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

[threadpool]
num_workers = 4      # å·¥ä½œçº¿ç¨‹æ•°

[tuner]
enable = true                # å¯ç”¨è‡ªåŠ¨è°ƒä¼˜
latency_max_ms = 100.0      # å»¶è¿Ÿé˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
recall_min_pct = 0.85       # å¬å›ç‡é˜ˆå€¼
ef_delta = 5                # efè°ƒæ•´æ­¥é•¿
topk_delta = 2              # topKè°ƒæ•´æ­¥é•¿
check_interval_seconds = 30  # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

# SQLite æ•°æ®åº“é…ç½®
[sqlite]
db_path = "rag_store.db"       # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
vector_extension = "sqlite_vec" # å‘é‡æ‰©å±•å
vector_dimension = 768         # å‘é‡ç»´åº¦
enable_fts5 = true            # å¯ç”¨ FTS5 å…¨æ–‡æ£€ç´¢
enable_wal = true             # å¯ç”¨ WAL æ¨¡å¼
cache_size = 10000            # ç¼“å­˜é¡µæ•°
busy_timeout = 30000          # å¿™ç­‰å¾…è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
fts5_limit = 50              # FTS5 æ£€ç´¢ç»“æœæ•°é‡
vector_limit = 50            # å‘é‡æ£€ç´¢ç»“æœæ•°é‡

# æ··åˆ RAG ç³»ç»Ÿé…ç½®
[hybrid]
enable = true                    # å¯ç”¨æ··åˆ RAG ç³»ç»Ÿ
hot_threshold = 3               # çƒ­æ•°æ®è®¿é—®æ¬¡æ•°é˜ˆå€¼
memory_capacity = 1000          # å†…å­˜å±‚æœ€å¤§æ–‡æ¡£æ•°
auto_optimize_interval = 300    # è‡ªåŠ¨ä¼˜åŒ–é—´éš”ï¼ˆç§’ï¼‰
enable_smart_caching = true     # å¯ç”¨æ™ºèƒ½ç¼“å­˜
parallel_search = true          # å¹¶è¡Œæœç´¢å†…å­˜å’ŒSQLite
memory_first = true             # ä¼˜å…ˆä»å†…å­˜å±‚æœç´¢
result_merge_method = "score"   # ç»“æœåˆå¹¶æ–¹å¼ï¼šscore/relevance
max_results_per_layer = 20      # æ¯å±‚æœ€å¤§ç»“æœæ•°
enable_benchmark = true         # å¯ç”¨æ€§èƒ½åŸºå‡†æµ‹è¯•
stats_interval = 100           # ç»Ÿè®¡ä¿¡æ¯æ›´æ–°é—´éš”
cache_hit_threshold = 0.8      # ç¼“å­˜å‘½ä¸­ç‡é˜ˆå€¼
```

### 2. SQLite æ•°æ®åº“ç³»ç»Ÿ

æ¡†æ¶æä¾›åŸºäº SQLite çš„æŒä¹…åŒ–å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½ï¼š

#### 2.1 æ•°æ®åº“åˆå§‹åŒ–

```cpp
#include "rag/sqlite_retriever.h"

// åˆ›å»º SQLite RAG ç³»ç»Ÿ
SQLiteRAGSystem rag_system("./rag_config.toml");

// åˆå§‹åŒ–æ•°æ®åº“å’Œç´¢å¼•
if (!rag_system.initialize()) {
    std::cerr << "Failed to initialize database" << std::endl;
    return 1;
}
```

#### 2.2 æ–‡æ¡£å­˜å‚¨

```cpp
// åˆ›å»ºæ–‡æ¡£
std::vector<Chunk> documents;
Chunk doc;
doc.doc_id = "tech_article_001";
doc.seq_no = 0;
doc.topic = "Machine Learning";
doc.text = "Machine learning algorithms can automatically learn from data...";
documents.push_back(doc);

// åŠ è½½åˆ°æ•°æ®åº“ï¼ˆè‡ªåŠ¨åˆ›å»º FTS5 ç´¢å¼•å’Œå‘é‡åµŒå…¥ï¼‰
auto loaded_count = rag_system.load_documents(documents);
std::cout << "Loaded " << loaded_count << " documents" << std::endl;
```

#### 2.3 æ£€ç´¢æŸ¥è¯¢

```cpp
// æ··åˆæ£€ç´¢ï¼ˆFTS5 + å‘é‡ï¼‰
auto results = rag_system.search("machine learning algorithms", 10);

for (const auto& result : results) {
    std::cout << "Doc ID: " << result.doc_id << std::endl;
    std::cout << "Topic: " << result.topic << std::endl;
    std::cout << "Score: " << result.score << std::endl;
    std::cout << "Content: " << result.content.substr(0, 100) << "..." << std::endl;
    std::cout << "---" << std::endl;
}
```

#### 2.4 æ£€ç´¢ç­–ç•¥

æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥ï¼š

```cpp
auto retriever = rag_system.get_retriever();

// ä»…æ–‡æœ¬æ£€ç´¢ï¼ˆFTS5 + BM25ï¼‰
auto text_results = retriever->query_text_only("machine learning", 5);

// ä»…å‘é‡æ£€ç´¢
auto vector_results = retriever->query_vector_only("artificial intelligence", 5);

// æ··åˆæ£€ç´¢ï¼ˆæ¨èï¼‰
auto hybrid_results = retriever->query_hybrid("deep learning networks", 5);

// å¼‚æ­¥æŸ¥è¯¢
auto future_results = retriever->query_async("neural networks", 5);
auto async_results = future_results.get();
```

#### 2.5 æ•°æ®åº“ç®¡ç†

```cpp
// è·å–æ•°æ®åº“ç»Ÿè®¡
auto stats = rag_system.get_system_stats();
std::cout << "Total chunks: " << stats.total_chunks << std::endl;
std::cout << "Total embeddings: " << stats.total_embeddings << std::endl;
std::cout << "Database size: " << stats.db_size_mb << " MB" << std::endl;
std::cout << "Last update: " << stats.last_update << std::endl;

// æ¸…ç©ºæ‰€æœ‰æ•°æ®
retriever->clear_all_data();
```

### 3. å¤šè¯­è¨€Tokenizer

æ”¯æŒè‹±æ–‡ã€ä¸­æ–‡å’Œæ··åˆè¯­è¨€çš„æ™ºèƒ½åˆ†è¯ï¼š

```cpp
// é…ç½®åˆ†è¯å™¨
TokenizerConfig config;
config.lowercase = true;                    // å¯ç”¨å°å†™è½¬æ¢
config.remove_punctuation = true;           // ç§»é™¤æ ‡ç‚¹ç¬¦å·
config.filter_stopwords = true;            // è¿‡æ»¤åœç”¨è¯
config.enable_chinese_segmentation = true;  // å¯ç”¨ä¸­æ–‡åˆ†è¯

Tokenizer tokenizer(config);

// è‡ªåŠ¨è¯­è¨€æ£€æµ‹
auto language = tokenizer.detect_language("æœºå™¨å­¦ä¹ å’ŒMachine Learning");
// è¿”å›: Language::MIXED

// åˆ†è¯å¤„ç†
auto tokens = tokenizer.tokenize("Natural Language Processingè‡ªç„¶è¯­è¨€å¤„ç†");
// è¿”å›: ["natural", "language", "processing", "è‡ªç„¶è¯­è¨€", "å¤„ç†"]
```

### 3. BM25æ£€ç´¢å™¨

é«˜æ€§èƒ½çš„BM25æ–‡æœ¬ç›¸å…³æ€§è®¡ç®—ï¼š

```cpp
// åˆ›å»ºBM25ç´¢å¼•å™¨
BM25Config bm25_config;
bm25_config.k1 = 1.2;  // è°ƒèŠ‚è¯é¢‘é¥±å’Œåº¦
bm25_config.b = 0.75;  // è°ƒèŠ‚æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–

BM25Indexer bm25(bm25_config);

// è®¾ç½®é«˜çº§åˆ†è¯å™¨
TokenizerConfig tokenizer_config;
tokenizer_config.filter_stopwords = true;
bm25.set_tokenizer_config(tokenizer_config);

// æ„å»ºç´¢å¼•
std::vector<Chunk> documents = load_documents();
bm25.fit(documents);

// æ‰§è¡ŒæŸ¥è¯¢
auto results = bm25.query_text("machine learning algorithms", 10);
// è¿”å›: vector<pair<size_t, double>> - (æ–‡æ¡£ç´¢å¼•, BM25åˆ†æ•°)
```

### 4. èåˆæ£€ç´¢å™¨

é›†æˆBM25å’ŒHNSWçš„å¤šç­–ç•¥èåˆæ£€ç´¢ï¼š

```cpp
// é…ç½®èåˆæ£€ç´¢å™¨
FusionRetrieverConfig config;
config.strategy = FusionStrategy::HYBRID;  // æ··åˆç­–ç•¥
config.bm25_weight = 0.6;                 // BM25æƒé‡
config.vector_weight = 0.4;               // å‘é‡æƒé‡

auto retriever = std::make_shared<FusionRetriever>(config);
retriever->fit(documents);

// åŒæ­¥æŸ¥è¯¢
auto results = retriever->query("deep learning", 5);

// å¼‚æ­¥æŸ¥è¯¢
auto future = retriever->query_async("neural networks", 5);
auto async_results = future.get();

// åˆ‡æ¢èåˆç­–ç•¥
config.strategy = FusionStrategy::RRF;  // ä½¿ç”¨RRFèåˆ
retriever->update_config(config);
```

#### èåˆç­–ç•¥è¯´æ˜

1. **BM25_ONLY**: ä»…ä½¿ç”¨BM25æ–‡æœ¬æ£€ç´¢
2. **VECTOR_ONLY**: ä»…ä½¿ç”¨HNSWå‘é‡æ£€ç´¢
3. **HYBRID**: åŠ æƒèåˆBM25å’Œå‘é‡åˆ†æ•°
4. **RRF**: å€’æ•°æ’åèåˆï¼ˆReciprocal Rank Fusionï¼‰

### 5. LRUç¼“å­˜

é«˜æ€§èƒ½çš„æŸ¥è¯¢ç»“æœç¼“å­˜ç³»ç»Ÿï¼š

```cpp
// é…ç½®ç¼“å­˜
CacheConfig cache_config;
cache_config.capacity = 1000;      // æœ€å¤§ç¼“å­˜é¡¹æ•°
cache_config.ttl_seconds = 3600;   // 1å°æ—¶è¿‡æœŸ

LRUCache cache(cache_config);

// ç¼“å­˜æŸ¥è¯¢ç»“æœ
Retrieval result;
result.top_chunks = {1, 3, 5};
result.timestamp = std::time(nullptr);
cache.put("machine learning", result);

// è·å–ç¼“å­˜
Retrieval cached;
if (cache.get("machine learning", cached)) {
    std::cout << "Cache hit!" << std::endl;
} else {
    std::cout << "Cache miss!" << std::endl;
}
```

### 6. çº¿ç¨‹æ± 

é«˜æ•ˆçš„å¹¶å‘ä»»åŠ¡å¤„ç†ï¼š

```cpp
// åˆ›å»ºçº¿ç¨‹æ± 
ThreadPoolConfig config;
config.num_workers = 8;  // 8ä¸ªå·¥ä½œçº¿ç¨‹

ThreadPool pool(config);

// æäº¤ä»»åŠ¡
auto future1 = pool.submit([&]{ return bm25.query(terms, 10); });
auto future2 = pool.submit([&]{ return hnsw.search(embedding, 10); });

// ç­‰å¾…ç»“æœ
auto bm25_results = future1.get();
auto hnsw_results = future2.get();
```

### 8. æ··åˆRAGç³»ç»Ÿ ğŸ”¥

**ç»ˆæè§£å†³æ–¹æ¡ˆï¼šå†…å­˜RAG + SQLite RAG å®Œç¾ç»“åˆ**

æ··åˆRAGç³»ç»Ÿæ˜¯æ¡†æ¶çš„æ ¸å¿ƒç‰¹æ€§ï¼Œå®ƒå°†å†…å­˜RAGå’ŒSQLite RAGçš„ä¼˜åŠ¿å®Œç¾ç»“åˆï¼Œå®ç°äº†**çƒ­æ•°æ®å†…å­˜ç¼“å­˜ + å†·æ•°æ®æŒä¹…åŒ–å­˜å‚¨**çš„åŒå±‚æ¶æ„ã€‚

#### 8.1 æ¶æ„è®¾è®¡ç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ··åˆRAGç³»ç»Ÿæ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”¥ çƒ­æ•°æ®å±‚ (å†…å­˜)  â”‚  â„ï¸ å†·æ•°æ®å±‚ (SQLite)                 â”‚
â”‚  â€¢ BM25 + HNSW     â”‚  â€¢ FTS5 + Vector                     â”‚
â”‚  â€¢ æ¯«ç§’çº§å“åº”        â”‚  â€¢ æ— é™å®¹é‡                          â”‚
â”‚  â€¢ é«˜é¢‘è®¿é—®æ•°æ®      â”‚  â€¢ æ•°æ®æŒä¹…åŒ–                        â”‚
â”‚  â€¢ LRUè‡ªåŠ¨ç®¡ç†      â”‚  â€¢ ACIDäº‹åŠ¡ä¿è¯                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              æ™ºèƒ½æ•°æ®åˆ†å±‚ç®¡ç†å™¨                               â”‚
â”‚  â€¢ è‡ªåŠ¨çƒ­ç‚¹è¯†åˆ«      â€¢ åŠ¨æ€æ•°æ®è¿ç§»      â€¢ ç»Ÿä¸€æ£€ç´¢æ¥å£       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 8.2 æ ¸å¿ƒä¼˜åŠ¿

- **ğŸš€ æè‡´æ€§èƒ½**: çƒ­æ•°æ®å†…å­˜æ£€ç´¢ï¼Œå¹³å‡å“åº”æ—¶é—´ < 1ms
- **ğŸ“¦ æ— é™å®¹é‡**: å†·æ•°æ®SQLiteå­˜å‚¨ï¼Œæ”¯æŒTBçº§æ–‡æ¡£åº“
- **ğŸ§  æ™ºèƒ½åˆ†å±‚**: åŸºäºè®¿é—®æ¨¡å¼è‡ªåŠ¨è¯†åˆ«çƒ­ç‚¹æ•°æ®
- **ğŸ”„ æ— ç¼åˆ‡æ¢**: é€æ˜çš„æ•°æ®è¿ç§»ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
- **âš¡ å¹¶è¡Œæ£€ç´¢**: åŒå±‚åŒæ—¶æ£€ç´¢ï¼Œæ™ºèƒ½ç»“æœåˆå¹¶
- **ğŸ’¾ æ•°æ®å®‰å…¨**: SQLite ACIDä¿è¯ï¼Œæ”¯æŒå¤‡ä»½æ¢å¤

#### 8.3 å¿«é€Ÿå¼€å§‹

```cpp
#include "rag/hybrid_rag_system.h"

// 1. åˆ›å»ºæ··åˆRAGç³»ç»Ÿ
HybridRAGSystem hybrid_rag("rag_config.toml");

// 2. åŠ è½½æ–‡æ¡£ï¼ˆè‡ªåŠ¨åˆ†å±‚å­˜å‚¨ï¼‰
std::vector<Chunk> documents = load_large_dataset();
auto loaded_count = hybrid_rag.load_documents(documents);

// 3. æ™ºèƒ½æ£€ç´¢ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼‰
auto results = hybrid_rag.search("æœºå™¨å­¦ä¹ ç®—æ³•", 10);

// 4. æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
hybrid_rag.print_system_stats();
```

#### 8.4 å®Œæ•´ç¤ºä¾‹ç¨‹åº

æ¡†æ¶æä¾›äº†å®Œæ•´çš„æ··åˆRAGæ¼”ç¤ºç¨‹åºï¼š

```bash
# ç¼–è¯‘æ··åˆRAGæ¼”ç¤º
cd rag/example/build
make hybrid_rag_demo

# è¿è¡Œæ¼”ç¤º
./hybrid_rag_demo
```

æ¼”ç¤ºç¨‹åºå±•ç¤ºäº†ï¼š

- ğŸ“š **å¤§è§„æ¨¡æ•°æ®åŠ è½½**: 36ä¸ªæ–‡æ¡£çš„åŒå±‚å­˜å‚¨
- ğŸ” **å¤šè½®æŸ¥è¯¢æ¨¡æ‹Ÿ**: æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è®¿é—®æ¨¡å¼
- ğŸ“Š **çƒ­ç‚¹æ•°æ®è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«é«˜é¢‘æŸ¥è¯¢æ–‡æ¡£
- ğŸ”„ **æ•°æ®åˆ†å±‚ä¼˜åŒ–**: çƒ­æ•°æ®è‡ªåŠ¨è¿ç§»åˆ°å†…å­˜å±‚
- âš¡ **æ€§èƒ½åŸºå‡†æµ‹è¯•**: 1298 QPS çš„æŸ¥è¯¢ååé‡

#### 8.5 æ™ºèƒ½æ•°æ®åˆ†å±‚ç­–ç•¥

```cpp
// é…ç½®çƒ­ç‚¹è¯†åˆ«å‚æ•°
hybrid_rag.set_hot_threshold(3);        // è®¿é—®3æ¬¡ä»¥ä¸Šä¸ºçƒ­æ•°æ®
hybrid_rag.set_memory_capacity(1000);   // å†…å­˜å±‚æœ€å¤§å®¹é‡

// æ‰‹åŠ¨è§¦å‘åˆ†å±‚ä¼˜åŒ–
hybrid_rag.optimize_data_distribution();

// æŸ¥çœ‹çƒ­ç‚¹ç»Ÿè®¡
auto stats = hybrid_rag.get_access_stats();
std::cout << "çƒ­æ•°æ®æ–‡æ¡£æ•°: " << stats.hot_document_count << std::endl;
std::cout << "å†…å­˜å‘½ä¸­ç‡: " << stats.memory_hit_rate << "%" << std::endl;
```

#### 8.6 æ€§èƒ½ç›‘æ§

```cpp
// è¿è¡ŒåŸºå‡†æµ‹è¯•
std::vector<std::string> queries = {
    "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "æ•°æ®ç§‘å­¦"
};
hybrid_rag.run_benchmark(queries);

// è¾“å‡º:
// ğŸ“ˆ åŸºå‡†æµ‹è¯•æ±‡æ€»:
//   â€¢ å¹³å‡æŸ¥è¯¢æ—¶é—´: 770.14Î¼s
//   â€¢ å¹³å‡ç»“æœæ•°é‡: 5.0 ä¸ª
//   â€¢ ç³»ç»Ÿååé‡: 1298 QPS
//   â€¢ å†…å­˜å‘½ä¸­ç‡: 50.0%
```

#### 8.7 å®é™…åº”ç”¨åœºæ™¯

- **ğŸ“– å¤§å‹çŸ¥è¯†åº“**: çƒ­é—¨æ–‡æ¡£å†…å­˜ç¼“å­˜ï¼Œå†å²æ–‡æ¡£æŒä¹…åŒ–
- **ğŸ¤– æ™ºèƒ½å®¢æœ**: å¸¸è§é—®é¢˜å¿«é€Ÿå“åº”ï¼Œé•¿å°¾é—®é¢˜å®Œæ•´è¦†ç›–
- **ğŸ”¬ ç§‘ç ”å¹³å°**: çƒ­ç‚¹è®ºæ–‡ç§’çº§æ£€ç´¢ï¼Œå…¨é‡æ–‡çŒ®æ— é™å­˜å‚¨
- **ğŸ’¼ ä¼ä¸šæœç´¢**: é‡è¦æ–‡æ¡£ä¼˜å…ˆçº§è®¿é—®ï¼Œå…¨éƒ¨èµ„æ–™ç»Ÿä¸€ç®¡ç†

æ··åˆRAGç³»ç»Ÿæ˜¯å¤„ç†å¤§è§„æ¨¡æ–‡æ¡£åº“çš„ç†æƒ³è§£å†³æ–¹æ¡ˆï¼Œå®ƒåœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„åŒæ—¶ï¼Œæä¾›äº†ä¼ä¸šçº§çš„æ•°æ®ç®¡ç†èƒ½åŠ›ã€‚

### 9. è‡ªåŠ¨è°ƒä¼˜å™¨

åŸºäºæ€§èƒ½æŒ‡æ ‡çš„å‚æ•°è‡ªåŠ¨ä¼˜åŒ–ï¼š

```cpp
// é…ç½®è°ƒä¼˜å™¨
TunerConfig config;
config.enable = true;
config.latency_max_ms = 100.0;     // å»¶è¿Ÿé˜ˆå€¼100ms
config.recall_min_pct = 0.85;      // å¬å›ç‡é˜ˆå€¼85%
config.check_interval_seconds = 30; // 30ç§’æ£€æŸ¥ä¸€æ¬¡

// å®šä¹‰ç›‘æ§å‡½æ•°
auto latency_monitor = []() -> double {
    return getCurrentLatency();  // è¿”å›å½“å‰å¹³å‡å»¶è¿Ÿ
};

auto recall_monitor = []() -> double {
    return getCurrentRecall();   // è¿”å›å½“å‰å¬å›ç‡
};

// åˆ›å»ºè°ƒä¼˜å™¨
AutoTuner tuner(config, latency_monitor, recall_monitor);

// å¯åŠ¨è‡ªåŠ¨è°ƒä¼˜
tuner.start();

// è·å–å½“å‰å‚æ•°
auto params = tuner.params();
std::cout << "Current ef: " << params.ef
          << ", topK: " << params.topK << std::endl;

// åœæ­¢è°ƒä¼˜
tuner.stop();
```

## ğŸ§ª æµ‹è¯•ç”¨ä¾‹

### åŠŸèƒ½æµ‹è¯•

é¡¹ç›®åŒ…å«å…¨é¢çš„åŠŸèƒ½æµ‹è¯•ï¼ŒéªŒè¯å„ä¸ªæ¨¡å—çš„æ­£ç¡®æ€§ï¼š

```bash
# ç¼–è¯‘å¹¶è¿è¡Œç»¼åˆæµ‹è¯•
cd rag/example/build
./rag_example
```

æµ‹è¯•è¦†ç›–å†…å®¹ï¼š
- âœ… å¤šè¯­è¨€åˆ†è¯å™¨æµ‹è¯•
- âœ… BM25æ£€ç´¢ç²¾åº¦æµ‹è¯•
- âœ… èåˆæ£€ç´¢ç­–ç•¥å¯¹æ¯”
- âœ… LRUç¼“å­˜å‘½ä¸­ç‡æµ‹è¯•
- âœ… å¹¶å‘æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
- âœ… è‡ªåŠ¨è°ƒä¼˜å‚æ•°å˜åŒ–æµ‹è¯•
- âœ… ç«¯åˆ°ç«¯RAGæµç¨‹æµ‹è¯•

### æ€§èƒ½åŸºå‡†

åœ¨Intel i7-8700K @ 3.70GHzï¼Œ32GB RAMç¯å¢ƒä¸‹çš„æ€§èƒ½è¡¨ç°ï¼š

| æ“ä½œ | å»¶è¿Ÿ | ååé‡ |
|------|------|--------|
| BM25æŸ¥è¯¢ | ~50Î¼s | 20,000 QPS |
| HNSWæŸ¥è¯¢ | ~200Î¼s | 5,000 QPS |
| èåˆæŸ¥è¯¢ | ~300Î¼s | 3,300 QPS |
| ç¼“å­˜å‘½ä¸­ | ~1Î¼s | 1,000,000 QPS |

### å†…å­˜å ç”¨

| ç»„ä»¶ | 1ä¸‡æ–‡æ¡£ | 10ä¸‡æ–‡æ¡£ | 100ä¸‡æ–‡æ¡£ |
|------|---------|----------|-----------|
| BM25ç´¢å¼• | ~50MB | ~500MB | ~5GB |
| HNSWç´¢å¼• | ~100MB | ~1GB | ~10GB |
| LRUç¼“å­˜ | ~10MB | ~10MB | ~10MB |

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰åˆ†è¯å™¨

```cpp
class CustomTokenizer : public TokenizerInterface {
public:
    std::vector<std::string> tokenize(const std::string& text) override {
        // å®ç°è‡ªå®šä¹‰åˆ†è¯é€»è¾‘
        return custom_tokenize(text);
    }

    }

    Language detect_language(const std::string& text) override {
        // å®ç°è¯­è¨€æ£€æµ‹é€»è¾‘
        return detect_custom_language(text);
    }
};
```

## ğŸ¯ å®Œæ•´åŠŸèƒ½ç¤ºä¾‹

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†æ‰€æœ‰ä¸»è¦åŠŸèƒ½çš„é›†æˆä½¿ç”¨ï¼š

```cpp
#include "rag/sqlite_retriever.h"
#include "rag/fusion_retriever.h"
#include "rag/config.h"
#include "rag/thread_pool.h"
#include "rag/lru_cache.h"

class ComprehensiveRAGDemo {
private:
    std::unique_ptr<SQLiteRAGSystem> sqlite_rag_;
    std::unique_ptr<FusionRetriever> memory_rag_;
    std::unique_ptr<ThreadPool> thread_pool_;
    std::unique_ptr<LRUCache<std::string, std::vector<SQLiteSearchResult>>> cache_;

public:
    ComprehensiveRAGDemo(const std::string& config_path) {
        // 1. åŠ è½½é…ç½®
        auto config = ConfigLoader::load(config_path);

        // 2. åˆå§‹åŒ–SQLite RAGç³»ç»Ÿ
        sqlite_rag_ = std::make_unique<SQLiteRAGSystem>(config_path);
        if (!sqlite_rag_->initialize()) {
            throw std::runtime_error("Failed to initialize SQLite RAG system");
        }

        // 3. åˆå§‹åŒ–å†…å­˜RAGç³»ç»Ÿ
        memory_rag_ = FusionRetriever::from_config(*config);

        // 4. åˆå§‹åŒ–çº¿ç¨‹æ± 
        thread_pool_ = std::make_unique<ThreadPool>(config->threadpool.num_workers);

        // 5. åˆå§‹åŒ–ç¼“å­˜
        cache_ = std::make_unique<LRUCache<std::string, std::vector<SQLiteSearchResult>>>(
            config->cache.capacity, config->cache.ttl_seconds);
    }

    // æ··åˆæ£€ç´¢ï¼šåŒæ—¶ä½¿ç”¨å†…å­˜å’ŒSQLiteç³»ç»Ÿ
    std::vector<SearchResult> hybrid_search(const std::string& query, int limit = 10) {
        // å¹¶è¡Œæ‰§è¡Œä¸¤ç§æ£€ç´¢
        auto sqlite_future = thread_pool_->submit([this, query, limit]() {
            return sqlite_rag_->search(query, limit);
        });

        auto memory_future = thread_pool_->submit([this, query, limit]() {
            return memory_rag_->query(query, limit);
        });

        // è·å–ç»“æœ
        auto sqlite_results = sqlite_future.get();
        auto memory_results = memory_future.get();

        // åˆå¹¶å’Œé‡æ’åº
        return merge_and_rerank(sqlite_results, memory_results, query, limit);
    }

    // æ™ºèƒ½æŸ¥è¯¢è·¯ç”±
    std::vector<SearchResult> smart_search(const std::string& query, int limit = 10) {
        // 1. æ£€æŸ¥ç¼“å­˜
        auto cached_result = cache_->get(query);
        if (cached_result) {
            std::cout << "Cache hit for query: " << query << std::endl;
            return convert_to_search_result(*cached_result);
        }

        // 2. åˆ†ææŸ¥è¯¢ç‰¹å¾
        QueryType query_type = analyze_query(query);

        std::vector<SearchResult> results;

        switch (query_type) {
            case QueryType::FACTUAL:
                // äº‹å®æŸ¥è¯¢ä¼˜å…ˆä½¿ç”¨SQLite FTS5
                results = convert_to_search_result(sqlite_rag_->search(query, limit));
                break;

            case QueryType::SEMANTIC:
                // è¯­ä¹‰æŸ¥è¯¢ä¼˜å…ˆä½¿ç”¨å‘é‡æ£€ç´¢
                results = convert_to_search_result(memory_rag_->query(query, limit));
                break;

            case QueryType::COMPLEX:
                // å¤æ‚æŸ¥è¯¢ä½¿ç”¨æ··åˆæ£€ç´¢
                results = hybrid_search(query, limit);
                break;
        }

        // 3. æ›´æ–°ç¼“å­˜
        cache_->put(query, convert_from_search_result(results));

        return results;
    }

    // æ‰¹é‡æ–‡æ¡£å¤„ç†
    void batch_load_documents(const std::vector<std::string>& file_paths) {
        std::vector<Chunk> all_chunks;

        // å¹¶è¡Œå¤„ç†æ–‡ä»¶
        std::vector<std::future<std::vector<Chunk>>> futures;

        for (const auto& file_path : file_paths) {
            auto future = thread_pool_->submit([this, file_path]() {
                return process_document_file(file_path);
            });
            futures.push_back(std::move(future));
        }

        // æ”¶é›†æ‰€æœ‰chunks
        for (auto& future : futures) {
            auto chunks = future.get();
            all_chunks.insert(all_chunks.end(), chunks.begin(), chunks.end());
        }

        std::cout << "Processed " << all_chunks.size() << " chunks from "
                  << file_paths.size() << " files" << std::endl;

        // åŒæ—¶åŠ è½½åˆ°ä¸¤ä¸ªç³»ç»Ÿ
        auto sqlite_future = thread_pool_->submit([this, &all_chunks]() {
            return sqlite_rag_->load_documents(all_chunks);
        });

        auto memory_future = thread_pool_->submit([this, &all_chunks]() {
            memory_rag_->fit(all_chunks);
        });

        auto sqlite_loaded = sqlite_future.get();
        memory_future.get();  // ç­‰å¾…å†…å­˜ç´¢å¼•å®Œæˆ

        std::cout << "Loaded " << sqlite_loaded << " documents to SQLite" << std::endl;
        std::cout << "Built in-memory index for " << all_chunks.size() << " chunks" << std::endl;
    }

    // æ€§èƒ½ç›‘æ§
    void print_performance_stats() {
        // SQLiteç»Ÿè®¡
        auto sqlite_stats = sqlite_rag_->get_system_stats();
        std::cout << "\nğŸ“Š SQLite RAG Statistics:" << std::endl;
        std::cout << "   Documents: " << sqlite_stats.total_chunks << std::endl;
        std::cout << "   Embeddings: " << sqlite_stats.total_embeddings << std::endl;
        std::cout << "   DB Size: " << sqlite_stats.db_size_mb << " MB" << std::endl;

        // ç¼“å­˜ç»Ÿè®¡
        auto cache_stats = cache_->get_stats();
        std::cout << "\nğŸ’¾ Cache Statistics:" << std::endl;
        std::cout << "   Hit Rate: " << (cache_stats.hit_rate * 100) << "%" << std::endl;
        std::cout << "   Size: " << cache_stats.size << "/" << cache_stats.capacity << std::endl;

        // çº¿ç¨‹æ± ç»Ÿè®¡
        std::cout << "\nğŸ§µ Thread Pool Statistics:" << std::endl;
        std::cout << "   Active Threads: " << thread_pool_->active_count() << std::endl;
        std::cout << "   Queue Size: " << thread_pool_->queue_size() << std::endl;
    }

private:
    enum class QueryType { FACTUAL, SEMANTIC, COMPLEX };

    QueryType analyze_query(const std::string& query) {
        // ç®€å•çš„æŸ¥è¯¢åˆ†æé€»è¾‘
        if (query.find("what") != std::string::npos ||
            query.find("when") != std::string::npos ||
            query.find("where") != std::string::npos) {
            return QueryType::FACTUAL;
        }

        if (query.length() > 50 ||
            std::count(query.begin(), query.end(), ' ') > 8) {
            return QueryType::COMPLEX;
        }

        return QueryType::SEMANTIC;
    }

    std::vector<Chunk> process_document_file(const std::string& file_path) {
        // æ–‡æ¡£å¤„ç†é€»è¾‘
        std::vector<Chunk> chunks;
        // ... å®ç°æ–‡æ¡£è§£æå’Œåˆ†å—
        return chunks;
    }

    std::vector<SearchResult> merge_and_rerank(
        const std::vector<SQLiteSearchResult>& sqlite_results,
        const std::vector<RetrievalResult>& memory_results,
        const std::string& query,
        int limit) {
        // ç»“æœåˆå¹¶å’Œé‡æ’åºé€»è¾‘
        std::vector<SearchResult> merged;
        // ... å®ç°åˆå¹¶é€»è¾‘
        return merged;
    }
};

// ä½¿ç”¨ç¤ºä¾‹
int main() {
    try {
        ComprehensiveRAGDemo demo("rag_config.toml");

        // 1. æ‰¹é‡åŠ è½½æ–‡æ¡£
        std::vector<std::string> document_files = {
            "docs/machine_learning.pdf",
            "docs/deep_learning.md",
            "docs/ai_ethics.txt"
        };
        demo.batch_load_documents(document_files);

        // 2. æ™ºèƒ½æŸ¥è¯¢æµ‹è¯•
        std::vector<std::string> test_queries = {
            "What is machine learning?",           // äº‹å®æŸ¥è¯¢
            "æ·±åº¦å­¦ä¹ çš„å‘å±•å†ç¨‹å’Œæœªæ¥è¶‹åŠ¿",              // è¯­ä¹‰æŸ¥è¯¢
            "How does machine learning relate to artificial intelligence and what are the ethical implications?"  // å¤æ‚æŸ¥è¯¢
        };

        for (const auto& query : test_queries) {
            std::cout << "\nğŸ” Query: " << query << std::endl;
            auto start = std::chrono::high_resolution_clock::now();

            auto results = demo.smart_search(query, 5);

            auto end = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);

            std::cout << "â±ï¸  Search completed in " << duration.count() << "Î¼s" << std::endl;
            std::cout << "ğŸ“Š Found " << results.size() << " results" << std::endl;

            for (size_t i = 0; i < std::min(size_t(3), results.size()); ++i) {
                std::cout << "   " << (i+1) << ". " << results[i].title
                         << " (Score: " << results[i].score << ")" << std::endl;
            }
        }

        // 3. æ€§èƒ½ç»Ÿè®¡
        demo.print_performance_stats();

    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
        return 1;
    }

    return 0;
}
```

## ğŸš€ éƒ¨ç½²ä¸ç”Ÿäº§ç¯å¢ƒ

### Docker å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile for production deployment
FROM ubuntu:22.04 AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    libsqlite3-dev \
    pkg-config \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install sqlite-vec extension
RUN wget https://github.com/asg017/sqlite-vec/releases/download/v0.0.1/sqlite-vec-0.0.1-linux-x86_64.tar.gz \
    && tar -xzf sqlite-vec-0.0.1-linux-x86_64.tar.gz \
    && cp sqlite-vec.so /usr/local/lib/ \
    && ldconfig

# Copy source and build
WORKDIR /app
COPY . .
RUN mkdir build && cd build \
    && cmake -DCMAKE_BUILD_TYPE=Release .. \
    && make -j$(nproc)

# Production image
FROM ubuntu:22.04

RUN apt-get update && apt-get install -y \
    libsqlite3-0 \
    && rm -rf /var/lib/apt/lists/*

# Copy built application and libraries
COPY --from=builder /usr/local/lib/sqlite-vec.so /usr/local/lib/
COPY --from=builder /app/build/rag_example /usr/local/bin/
COPY --from=builder /app/rag_config.toml /etc/rag/

# Create data directory
RUN mkdir -p /data && chown -R 1000:1000 /data

# Non-root user
USER 1000:1000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD /usr/local/bin/rag_example --health-check || exit 1

EXPOSE 8080
VOLUME ["/data"]

CMD ["/usr/local/bin/rag_example", "--config", "/etc/rag/rag_config.toml"]
```

### Kubernetes éƒ¨ç½²é…ç½®

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: humanus-rag
  labels:
    app: humanus-rag
spec:
  replicas: 3
  selector:
    matchLabels:
      app: humanus-rag
  template:
    metadata:
      labels:
        app: humanus-rag
    spec:
      containers:
      - name: rag-service
        image: humanus/rag:latest
        ports:
        - containerPort: 8080
        env:
        - name: CONFIG_PATH
          value: "/etc/rag/rag_config.toml"
        - name: DATA_PATH
          value: "/data"
        volumeMounts:
        - name: config-volume
          mountPath: /etc/rag
        - name: data-volume
          mountPath: /data
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
      volumes:
      - name: config-volume
        configMap:
          name: rag-config
      - name: data-volume
        persistentVolumeClaim:
          claimName: rag-data-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: humanus-rag-service
spec:
  selector:
    app: humanus-rag
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer
```

### ç›‘æ§å’Œå‘Šè­¦é…ç½®

```yaml
# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s

    scrape_configs:
    - job_name: 'humanus-rag'
      static_configs:
      - targets: ['humanus-rag-service:80']
      metrics_path: /metrics
      scrape_interval: 10s

    rule_files:
    - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

---
# Alert rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-alert-rules
data:
  rag.yml: |
    groups:
    - name: rag-alerts
      rules:
      - alert: RAGHighLatency
        expr: rag_query_duration_seconds_p95 > 0.5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "RAG query latency is high"
          description: "95th percentile latency is {{ $value }}s"

      - alert: RAGLowCacheHitRate
        expr: rag_cache_hit_rate < 0.7
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "RAG cache hit rate is low"
          description: "Cache hit rate is {{ $value }}"

      - alert: RAGDatabaseSize
        expr: rag_database_size_mb > 10000
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "RAG database size is large"
          description: "Database size is {{ $value }}MB"
```

## ğŸ“š API å‚è€ƒæ–‡æ¡£

### æ ¸å¿ƒç±»å‚è€ƒ

#### FusionRetriever

```cpp
class FusionRetriever {
public:
    /**
     * æ„é€ å‡½æ•°
     * @param config èåˆæ£€ç´¢å™¨é…ç½®
     */
    explicit FusionRetriever(const FusionRetrieverConfig& config);

    /**
     * ä»RAGé…ç½®åˆ›å»ºæ£€ç´¢å™¨
     * @param config RAGç³»ç»Ÿé…ç½®
     * @return æ£€ç´¢å™¨æ™ºèƒ½æŒ‡é’ˆ
     */
    static std::shared_ptr<FusionRetriever> from_config(const RAGConfig& config);

    /**
     * æ„å»ºç´¢å¼•
     * @param chunks æ–‡æ¡£å—é›†åˆ
     * @throws RAGException å½“ç´¢å¼•æ„å»ºå¤±è´¥æ—¶
     */
    void fit(const std::vector<Chunk>& chunks);

    /**
     * æ‰§è¡ŒæŸ¥è¯¢
     * @param query_text æŸ¥è¯¢æ–‡æœ¬
     * @param top_k è¿”å›ç»“æœæ•°é‡
     * @return æ£€ç´¢ç»“æœåˆ—è¡¨
     */
    std::vector<RetrievalResult> query(const std::string& query_text, int top_k = 10);

    /**
     * å¼‚æ­¥æŸ¥è¯¢
     * @param query_text æŸ¥è¯¢æ–‡æœ¬
     * @param top_k è¿”å›ç»“æœæ•°é‡
     * @return å¼‚æ­¥ç»“æœfuture
     */
    std::future<std::vector<RetrievalResult>> query_async(const std::string& query_text, int top_k = 10);

    /**
     * è·å–ç»Ÿè®¡ä¿¡æ¯
     * @return ç»Ÿè®¡ä¿¡æ¯ç»“æ„
     */
    IndexStats get_stats() const;

    /**
     * æ›´æ–°é…ç½®
     * @param config æ–°é…ç½®
     */
    void update_config(const FusionRetrieverConfig& config);
};
```

#### SQLiteRAGSystem

```cpp
class SQLiteRAGSystem {
public:
    /**
     * æ„é€ å‡½æ•°
     * @param config_path é…ç½®æ–‡ä»¶è·¯å¾„
     */
    explicit SQLiteRAGSystem(const std::string& config_path = "rag_config.toml");

    /**
     * åˆå§‹åŒ–ç³»ç»Ÿ
     * @return æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
     */
    bool initialize();

    /**
     * åŠ è½½æ–‡æ¡£é›†åˆ
     * @param documents æ–‡æ¡£åˆ—è¡¨
     * @return æˆåŠŸåŠ è½½çš„æ–‡æ¡£æ•°é‡
     */
    size_t load_documents(const std::vector<Chunk>& documents);

    /**
     * ä»æ–‡ä»¶åŠ è½½æ–‡æ¡£
     * @param file_path æ–‡ä»¶è·¯å¾„
     * @return æˆåŠŸåŠ è½½çš„æ–‡æ¡£æ•°é‡
     */
    size_t load_documents_from_file(const std::string& file_path);

    /**
     * æ‰§è¡Œæœç´¢
     * @param query æŸ¥è¯¢å­—ç¬¦ä¸²
     * @param limit ç»“æœæ•°é‡é™åˆ¶
     * @return æœç´¢ç»“æœåˆ—è¡¨
     */
    std::vector<SQLiteSearchResult> search(const std::string& query, int limit = 10);

    /**
     * å¼‚æ­¥æœç´¢
     * @param query æŸ¥è¯¢å­—ç¬¦ä¸²
     * @param limit ç»“æœæ•°é‡é™åˆ¶
     * @return å¼‚æ­¥æœç´¢ç»“æœ
     */
    std::future<std::vector<SQLiteSearchResult>> search_async(const std::string& query, int limit = 10);

    /**
     * è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
     * @return æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
     */
    SQLiteDB::DBStats get_system_stats();

    /**
     * æ¸…ç†å’Œä¼˜åŒ–æ•°æ®åº“
     */
    void optimize_database();

    /**
     * å¤‡ä»½æ•°æ®åº“
     * @param backup_path å¤‡ä»½æ–‡ä»¶è·¯å¾„
     * @return æ˜¯å¦å¤‡ä»½æˆåŠŸ
     */
    bool backup_database(const std::string& backup_path);
};
```

### é…ç½®ç»“æ„å‚è€ƒ

#### RAGConfig

```cpp
struct RAGConfig {
    struct ChunkConfig {
        int size = 512;
        int overlap = 128;
        int min_size = 64;
    } chunk;

    struct BM25Config {
        double k1 = 1.5;
        double b = 0.75;
    } bm25;

    struct HNSWConfig {
        int M = 16;
        int ef_construction = 200;
        int ef_query = 50;
    } hnsw;

    struct FusionConfig {
        std::string strategy = "hybrid";
        double bm25_weight = 0.6;
        double vector_weight = 0.4;
        double rrf_k = 60.0;
        bool enable_rerank = true;
        int max_candidates = 100;
    } fusion;

    struct CacheConfig {
        int capacity = 1024;
        int ttl_seconds = 3600;
    } cache;

    struct ThreadPoolConfig {
        int num_workers = 8;
    } threadpool;

    struct TunerConfig {
        bool enable = true;
        double latency_max_ms = 200.0;
        double recall_min_pct = 0.8;
        int ef_delta = 5;
        int topk_delta = 2;
        int check_interval_seconds = 10;
    } tuner;

    struct SQLiteConfig {
        std::string db_path = "rag_store.db";
        std::string vector_extension = "sqlite_vec";
        int vector_dimension = 768;
        bool enable_fts5 = true;
        bool enable_wal = true;
        int cache_size = 10000;
        int busy_timeout = 30000;
        int fts5_limit = 50;
        int vector_limit = 50;
    } sqlite;
};
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–å»ºè®®

```cpp
// 1. é¢„çƒ­ç¼“å­˜
void warm_up_cache(FusionRetriever& retriever) {
    std::vector<std::string> common_queries = {
        "machine learning",
        "artificial intelligence",
        "deep learning",
        "neural networks"
    };

    for (const auto& query : common_queries) {
        retriever.query(query, 10);  // é¢„çƒ­æŸ¥è¯¢
    }
}

// 2. æ‰¹é‡å¤„ç†ä¼˜åŒ–
void batch_process_documents(SQLiteRAGSystem& rag, const std::vector<std::string>& files) {
    const size_t batch_size = 100;

    for (size_t i = 0; i < files.size(); i += batch_size) {
        size_t end = std::min(i + batch_size, files.size());
        std::vector<std::string> batch(files.begin() + i, files.begin() + end);

        // å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
        std::vector<std::future<std::vector<Chunk>>> futures;
        for (const auto& file : batch) {
            futures.push_back(std::async(std::launch::async, [&file]() {
                return process_file(file);
            }));
        }

        // æ”¶é›†ç»“æœå¹¶æ‰¹é‡æ’å…¥
        std::vector<Chunk> batch_chunks;
        for (auto& future : futures) {
            auto chunks = future.get();
            batch_chunks.insert(batch_chunks.end(), chunks.begin(), chunks.end());
        }

        rag.load_documents(batch_chunks);
    }
}

// 3. å†…å­˜ä½¿ç”¨ä¼˜åŒ–
class MemoryOptimizedProcessor {
    static constexpr size_t MAX_MEMORY_MB = 1024;  // 1GB limit

public:
    void process_large_dataset(const std::string& dataset_path) {
        auto file_stream = std::ifstream(dataset_path);
        std::string line;
        std::vector<Chunk> buffer;
        size_t memory_usage = 0;

        while (std::getline(file_stream, line)) {
            auto chunk = parse_line(line);
            buffer.push_back(chunk);
            memory_usage += chunk.text.size();

            // å½“å†…å­˜ä½¿ç”¨è¶…è¿‡é™åˆ¶æ—¶ï¼Œå¤„ç†å½“å‰æ‰¹æ¬¡
            if (memory_usage > MAX_MEMORY_MB * 1024 * 1024) {
                process_batch(buffer);
                buffer.clear();
                memory_usage = 0;
            }
        }

        // å¤„ç†å‰©ä½™æ•°æ®
        if (!buffer.empty()) {
            process_batch(buffer);
        }
    }
};
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

```cpp
class RobustRAGService {
public:
    std::vector<SearchResult> search_with_fallback(const std::string& query, int limit) {
        try {
            // å°è¯•ä¸»è¦æ£€ç´¢æ–¹æ³•
            return primary_search(query, limit);
        } catch (const DatabaseException& e) {
            std::cerr << "Database error: " << e.what() << std::endl;
            // é™çº§åˆ°å¤‡ç”¨æ–¹æ³•
            return fallback_search(query, limit);
        } catch (const std::exception& e) {
            std::cerr << "Unexpected error: " << e.what() << std::endl;
            // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯å´©æºƒ
            return {};
        }
    }

private:
    std::vector<SearchResult> primary_search(const std::string& query, int limit) {
        // ä¸»è¦æ£€ç´¢é€»è¾‘
        if (sqlite_rag_->is_available()) {
            return sqlite_rag_->search(query, limit);
        } else {
            throw DatabaseException("SQLite RAG system not available");
        }
    }

    std::vector<SearchResult> fallback_search(const std::string& query, int limit) {
        // å¤‡ç”¨æ£€ç´¢é€»è¾‘ï¼ˆä½¿ç”¨å†…å­˜ç³»ç»Ÿï¼‰
        return memory_rag_->query(query, limit);
    }
};

// è‡ªå®šä¹‰å¼‚å¸¸ç±»
class RAGException : public std::exception {
protected:
    std::string message_;

public:
    explicit RAGException(const std::string& msg) : message_(msg) {}
    const char* what() const noexcept override { return message_.c_str(); }
};

class DatabaseException : public RAGException {
public:
    explicit DatabaseException(const std::string& msg)
        : RAGException("Database Error: " + msg) {}
};

class ConfigurationException : public RAGException {
public:
    explicit ConfigurationException(const std::string& msg)
        : RAGException("Configuration Error: " + msg) {}
};
```

### 3. ç›‘æ§ä¸æ—¥å¿—

```cpp
#include <spdlog/spdlog.h>
#include <prometheus/counter.h>
#include <prometheus/histogram.h>

class RAGMetrics {
private:
    std::shared_ptr<prometheus::Registry> registry_;
    prometheus::Counter* queries_total_;
    prometheus::Histogram* query_duration_;
    prometheus::Counter* cache_hits_;
    prometheus::Counter* cache_misses_;

public:
    RAGMetrics() {
        registry_ = std::make_shared<prometheus::Registry>();

        // æŸ¥è¯¢è®¡æ•°å™¨
        auto& counter_family = prometheus::BuildCounter()
            .Name("rag_queries_total")
            .Help("Total number of RAG queries")
            .Register(*registry_);
        queries_total_ = &counter_family.Add({{"type", "search"}});

        // æŸ¥è¯¢å»¶è¿Ÿç›´æ–¹å›¾
        auto& histogram_family = prometheus::BuildHistogram()
            .Name("rag_query_duration_seconds")
            .Help("RAG query duration in seconds")
            .Register(*registry_);
        query_duration_ = &histogram_family.Add({},
            {0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0});

        // ç¼“å­˜æŒ‡æ ‡
        auto& cache_family = prometheus::BuildCounter()
            .Name("rag_cache_operations_total")
            .Help("Total cache operations")
            .Register(*registry_);
        cache_hits_ = &cache_family.Add({{"result", "hit"}});
        cache_misses_ = &cache_family.Add({{"result", "miss"}});
    }

    void record_query(double duration_seconds) {
        queries_total_->Increment();
        query_duration_->Observe(duration_seconds);
    }

    void record_cache_hit() { cache_hits_->Increment(); }
    void record_cache_miss() { cache_misses_->Increment(); }

    std::shared_ptr<prometheus::Registry> get_registry() { return registry_; }
};

class InstrumentedRAGService {
private:
    std::unique_ptr<SQLiteRAGSystem> rag_system_;
    std::unique_ptr<RAGMetrics> metrics_;

public:
    InstrumentedRAGService(const std::string& config_path) {
        rag_system_ = std::make_unique<SQLiteRAGSystem>(config_path);
        metrics_ = std::make_unique<RAGMetrics>();

        // é…ç½®æ—¥å¿—
        spdlog::set_level(spdlog::level::info);
        spdlog::set_pattern("[%Y-%m-%d %H:%M:%S.%e] [%l] [%t] %v");
    }

    std::vector<SQLiteSearchResult> search(const std::string& query, int limit) {
        auto start = std::chrono::high_resolution_clock::now();

        spdlog::info("Processing search query: '{}', limit: {}", query, limit);

        try {
            auto results = rag_system_->search(query, limit);

            auto end = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration<double>(end - start).count();

            // è®°å½•æŒ‡æ ‡
            metrics_->record_query(duration);

            spdlog::info("Search completed successfully: {} results in {:.3f}s",
                        results.size(), duration);

            return results;

        } catch (const std::exception& e) {
            spdlog::error("Search failed for query '{}': {}", query, e.what());
            throw;
        }
    }
};
```

## ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

#### 1. ç¼–è¯‘é—®é¢˜

**é—®é¢˜**: C++17 ç‰¹æ€§ä¸æ”¯æŒ
```bash
error: 'std::optional' is not a member of 'std'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿ç¼–è¯‘å™¨ç‰ˆæœ¬
g++ --version  # éœ€è¦ 7.0+
clang++ --version  # éœ€è¦ 6.0+

# è®¾ç½® C++17 æ ‡å‡†
cmake -DCMAKE_CXX_STANDARD=17 ..
# æˆ–åœ¨ CMakeLists.txt ä¸­æ·»åŠ 
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
```

#### 2. SQLite æ‰©å±•é—®é¢˜

**é—®é¢˜**: å‘é‡æ‰©å±•åŠ è½½å¤±è´¥
```
Warning: Failed to load vector extension 'sqlite_vec'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³•1: ä¸‹è½½é¢„ç¼–è¯‘æ‰©å±•
wget https://github.com/asg017/sqlite-vec/releases/latest/download/sqlite-vec-linux-x86_64.tar.gz
tar -xzf sqlite-vec-linux-x86_64.tar.gz
sudo cp sqlite-vec.so /usr/local/lib/
sudo ldconfig

# æ–¹æ³•2: ä»æºç ç¼–è¯‘
git clone https://github.com/asg017/sqlite-vec.git
cd sqlite-vec
make loadable
sudo make install

# æ–¹æ³•3: è®¾ç½®æ‰©å±•è·¯å¾„
export LD_LIBRARY_PATH=/path/to/extensions:$LD_LIBRARY_PATH
```

#### 3. æ€§èƒ½é—®é¢˜

**é—®é¢˜**: æŸ¥è¯¢é€Ÿåº¦æ…¢
```cpp
// è¯Šæ–­å·¥å…·
class PerformanceDiagnostic {
public:
    void diagnose_slow_query(const std::string& query) {
        std::cout << "Diagnosing query: " << query << std::endl;

        // 1. æ£€æŸ¥æŸ¥è¯¢å¤æ‚åº¦
        auto complexity = analyze_query_complexity(query);
        std::cout << "Query complexity: " << complexity << std::endl;

        // 2. æ£€æŸ¥æ•°æ®åº“å¤§å°
        auto stats = rag_system_->get_system_stats();
        std::cout << "Database size: " << stats.db_size_mb << "MB" << std::endl;
        std::cout << "Total chunks: " << stats.total_chunks << std::endl;

        // 3. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        auto cache_stats = cache_->get_stats();
        std::cout << "Cache hit rate: " << (cache_stats.hit_rate * 100) << "%" << std::endl;

        // 4. æ¨èä¼˜åŒ–
        suggest_optimizations(complexity, stats, cache_stats);
    }

private:
    void suggest_optimizations(int complexity, const auto& db_stats, const auto& cache_stats) {
        if (complexity > 10) {
            std::cout << "ğŸ”§ Consider simplifying the query" << std::endl;
        }

        if (db_stats.db_size_mb > 1000) {
            std::cout << "ğŸ”§ Consider database partitioning" << std::endl;
        }

        if (cache_stats.hit_rate < 0.5) {
            std::cout << "ğŸ”§ Consider increasing cache size or TTL" << std::endl;
        }
    }
};
```

#### 4. å†…å­˜æ³„æ¼

**æ£€æµ‹å·¥å…·**:
```bash
# ä½¿ç”¨ Valgrind
valgrind --tool=memcheck --leak-check=full --show-leak-kinds=all ./rag_example

# ä½¿ç”¨ AddressSanitizer
g++ -fsanitize=address -g -o rag_example_debug *.cpp
./rag_example_debug

# ä½¿ç”¨ tcmalloc
env LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4" ./rag_example
```

**å¸¸è§å†…å­˜é—®é¢˜ä¿®å¤**:
```cpp
// 1. RAII åŸåˆ™
class SafeRAGService {
    std::unique_ptr<SQLiteRAGSystem> rag_;  // è‡ªåŠ¨æ¸…ç†

public:
    SafeRAGService(const std::string& config)
        : rag_(std::make_unique<SQLiteRAGSystem>(config)) {}

    // ææ„å‡½æ•°è‡ªåŠ¨è°ƒç”¨ï¼Œæ— éœ€æ‰‹åŠ¨é‡Šæ”¾
    ~SafeRAGService() = default;
};

// 2. é¿å…å¾ªç¯å¼•ç”¨
class DocumentIndex {
    std::vector<std::shared_ptr<Document>> documents_;
    std::weak_ptr<DocumentIndex> self_;  // ä½¿ç”¨ weak_ptr é¿å…å¾ªç¯

public:
    void set_self(std::shared_ptr<DocumentIndex> self) {
        self_ = self;
    }
};

// 3. åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡
void process_large_dataset() {
    {
        std::vector<Chunk> large_chunks = load_large_dataset();
        process_chunks(large_chunks);
        // large_chunks åœ¨ä½œç”¨åŸŸç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
    }

    // ç»§ç»­å…¶ä»–å¤„ç†ï¼Œå†…å­˜å·²é‡Šæ”¾
    other_processing();
}
```

## ğŸ“ æ”¯æŒä¸ç¤¾åŒº

### è·å–å¸®åŠ©

1. **ğŸ“š æ–‡æ¡£**: [å®Œæ•´æ–‡æ¡£](https://github.com/jblymq/RAG-CCC)
2. **ğŸ’¬ è®¨è®º**: [GitHub Discussions](https://github.com/jblymq/RAG-CCC/discussions)
3. **ğŸ› é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/jblymq/RAG-CCC/issues)
4. **ğŸ“§ é‚®ä»¶**: myth-lab@whu.edu.cn

### è´¡çŒ®ä»£ç 

```bash
# 1. Fork é¡¹ç›®
git clone https://github.com/jblymq/RAG-CCC.git

# 2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
git checkout -b feature/amazing-feature

# 3. æäº¤æ›´æ”¹
git commit -m 'feat: add amazing feature'

# 4. æ¨é€åˆ°åˆ†æ”¯
git push origin feature/amazing-feature

# 5. åˆ›å»º Pull Request
```

### ä»£ç è´¡çŒ®æŒ‡å—

1. **ä»£ç é£æ ¼**: éµå¾ª Google C++ Style Guide
2. **æµ‹è¯•**: ä¸ºæ–°åŠŸèƒ½æ·»åŠ å•å…ƒæµ‹è¯•
3. **æ–‡æ¡£**: æ›´æ–°ç›¸å…³æ–‡æ¡£
4. **æäº¤ä¿¡æ¯**: ä½¿ç”¨ [Conventional Commits](https://conventionalcommits.org/) æ ¼å¼

### ç¤¾åŒºè¡Œä¸ºå‡†åˆ™

æˆ‘ä»¬è‡´åŠ›äºåˆ›å»ºä¸€ä¸ªåŒ…å®¹ã€å‹å¥½çš„ç¤¾åŒºç¯å¢ƒã€‚è¯·éµå¾ªæˆ‘ä»¬çš„[è¡Œä¸ºå‡†åˆ™](CODE_OF_CONDUCT.md)ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®å’Œè´¡çŒ®è€…ï¼š

- **[SQLite](https://sqlite.org/)** - å¯é é«˜æ•ˆçš„æ•°æ®åº“å¼•æ“
- **[sqlite-vec](https://github.com/asg017/sqlite-vec)** - SQLite å‘é‡æ‰©å±•
- **[toml11](https://github.com/ToruNiina/toml11)** - ç°ä»£ C++ TOML è§£æå™¨
- **[spdlog](https://github.com/gabime/spdlog)** - å¿«é€Ÿ C++ æ—¥å¿—åº“
- **[Prometheus C++](https://github.com/jupp0r/prometheus-cpp)** - Prometheus æŒ‡æ ‡åº“

æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œç”¨æˆ·çš„æ”¯æŒä¸åé¦ˆï¼

---

<div align="center">

**[â­ Star](https://github.com/jblymq/RAG-CCC) æ­¤é¡¹ç›®** | **[ğŸ´ Fork](https://github.com/jblymq/RAG-CCC/fork) å¹¶è´¡çŒ®** | **[ğŸ“– é˜…è¯»æ–‡æ¡£](https://github.com/jblymq/RAG-CCC)** | **[ğŸ› æŠ¥å‘Šé—®é¢˜](https://github.com/jblymq/RAG-CCC/issues)**

**ç”± [WHU-MYTH-Lab](https://github.com/WHU-MYTH-Lab) ç”¨ â¤ï¸ åˆ¶ä½œ**

*è®© AI æ›´æ™ºèƒ½ï¼Œè®©æ£€ç´¢æ›´ç²¾å‡†*

</div>

// æ³¨å†Œè‡ªå®šä¹‰åˆ†è¯å™¨
BM25Indexer bm25;
bm25.set_custom_tokenizer(std::make_shared<CustomTokenizer>());
```

### è‡ªå®šä¹‰å‘é‡å­˜å‚¨

```cpp
class CustomVectorStore : public VectorStoreInterface {
public:
    void fit(const std::vector<Chunk>& chunks) override {
        // å®ç°è‡ªå®šä¹‰å‘é‡å­˜å‚¨æ„å»º
    }

    std::vector<RetrievalResult> search(
        const std::vector<float>& query_embedding,
        size_t top_k
    ) override {
        // å®ç°è‡ªå®šä¹‰å‘é‡æ£€ç´¢
        return custom_search(query_embedding, top_k);
    }
};
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

1. **BM25å‚æ•°è°ƒä¼˜**
   - `k1`: æ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼Œæ¨èèŒƒå›´[1.0, 2.0]
   - `b`: æ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–ï¼Œæ¨èèŒƒå›´[0.5, 1.0]

2. **HNSWå‚æ•°è°ƒä¼˜**
   - `M`: è¿æ¥æ•°ï¼Œå½±å“ç²¾åº¦å’Œå†…å­˜ï¼Œæ¨èèŒƒå›´[8, 32]
   - `ef_construction`: æ„å»ºæ—¶æœç´¢å®½åº¦ï¼Œæ¨è200-400
   - `ef_query`: æŸ¥è¯¢æ—¶æœç´¢å®½åº¦ï¼Œæ¨èèŒƒå›´[50, 200]

3. **ç¼“å­˜ä¼˜åŒ–**
   - æ ¹æ®QPSå’Œå¹³å‡æŸ¥è¯¢é•¿åº¦è®¾ç½®å®¹é‡
   - TTLè®¾ç½®è¦å¹³è¡¡æ–°é²œåº¦å’Œå‘½ä¸­ç‡

4. **çº¿ç¨‹æ± é…ç½®**
   - CPUå¯†é›†å‹ï¼šçº¿ç¨‹æ•° = CPUæ ¸å¿ƒæ•°
   - IOå¯†é›†å‹ï¼šçº¿ç¨‹æ•° = CPUæ ¸å¿ƒæ•° Ã— 2

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

### ä»£ç è§„èŒƒ

- éµå¾ªC++17æ ‡å‡†
- ä½¿ç”¨snake_caseå‘½åå˜é‡å’Œå‡½æ•°
- ä½¿ç”¨PascalCaseå‘½åç±»å’Œç»“æ„ä½“
- æ·»åŠ å¿…è¦çš„æ³¨é‡Šå’Œæ–‡æ¡£

## ğŸ“Š è·¯çº¿å›¾

### v1.1 (è®¡åˆ’ä¸­)
- [ ] æ”¯æŒæ›´å¤šå‘é‡æ•°æ®åº“ï¼ˆFaiss, Milvusï¼‰
- [ ] å¢åŠ Cross-Encoderé‡æ’åº
- [ ] æ”¯æŒå¤šæ¨¡æ€æ£€ç´¢ï¼ˆå›¾æ–‡æ··åˆï¼‰
- [ ] WebUIç®¡ç†ç•Œé¢

### v1.2 (è§„åˆ’ä¸­)
- [ ] åˆ†å¸ƒå¼éƒ¨ç½²æ”¯æŒ
- [ ] GPUåŠ é€Ÿå‘é‡è®¡ç®—
- [ ] æµå¼æ–‡æ¡£å¤„ç†
- [ ] RESTful APIæ¥å£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æº - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [HNSW](https://github.com/nmslib/hnswlib) - é«˜æ€§èƒ½å‘é‡æ£€ç´¢åº“
- [toml++](https://github.com/marzer/tomlplusplus) - TOMLè§£æåº“
- [spdlog](https://github.com/gabime/spdlog) - é«˜æ€§èƒ½æ—¥å¿—åº“

## ğŸ“ è”ç³»æˆ‘ä»¬

- é¡¹ç›®ä¸»é¡µ: https://github.com/jblymq/RAG-CCC
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/jblymq/RAG-CCC/issues)
- é‚®ç®±: myth-lab@whu.edu.cn

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼
